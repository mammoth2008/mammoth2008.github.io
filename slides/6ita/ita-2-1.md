### What is Machine Learning?

- Teaching computers to learn from data
- Making decisions or predictions
- No explicit programming for each task
- Automatically improve with experience

<!-- Lecture: Machine learning is a subfield of artificial intelligence that focuses on teaching computers to learn patterns from data. Instead of writing specific instructions for each task, machine learning algorithms allow computers to automatically improve their performance with more data and experience. This enables them to make decisions or predictions without being explicitly programmed to do so. -->

![Machine Learning](https://chat.openai.com/img/c04/machine-learning.png)

#### Machine Learning

### How Does It Work?

- Input data: examples, features, and labels
- Learning algorithm: processes the data
- Model: the result of the learning process
- Make predictions or decisions on new data

![Machine Learning Process](https://chat.openai.com/img/c04/machine-learning-process.png)

#### Machine Learning Process

### Why is it Important?

- Automate complex tasks
- Improve efficiency and accuracy
- Adapt to new data and situations
- Analyze and discover patterns in large datasets

![Machine Learning Applications](https://chat.openai.com/img/c04/machine-learning-applications.png)

#### Machine Learning Applications



### Important People in Machine Learning

- Alan Turing: Turing Test, early ideas of machine learning
- Arthur Samuel: Coined the term "machine learning"
- Frank Rosenblatt: Invented the perceptron
- Geoffrey Hinton: Pioneered deep learning and neural networks
- Yann LeCun: Convolutional Neural Networks (CNNs)
- Yoshua Bengio: Deep learning, recurrent neural networks
- Andrew Ng: Co-founder of Coursera, deep learning research

![Important People](https://chat.openai.com/img/c05/important-people.png)

#### Important People in Machine Learning
### 什么是机器学习？

- 教计算机从数据中学习
- 做出决定或预测
- 每个任务都没有明确的编程
- 随着经验的积累自动改进

<！--讲座。机器学习是人工智能的一个子领域，重点是教计算机从数据中学习模式。机器学习算法不是为每项任务编写具体的指令，而是让计算机随着更多的数据和经验自动提高其性能。这使它们能够在没有明确编程的情况下做出决定或预测。-->

![机器学习](https://chat.openai.com/img/c04/machine-learning.png)

#### 机器学习

### 它是如何工作的？

- 输入数据：例子、特征和标签
- 学习算法：处理数据
- 模型：学习过程的结果
- 对新数据进行预测或决策

![机器学习过程](https://chat.openai.com/img/c04/machine-learning-process.png)

#### 机器学习过程

###为什么它很重要？

- 实现复杂任务的自动化
- 提高效率和准确性
- 适应新的数据和情况
- 分析和发现大型数据集的模式

![机器学习应用](https://chat.openai.com/img/c04/machine-learning-applications.png)

#### 机器学习应用



###机器学习的重要人物

- 阿兰-图灵。图灵测试，机器学习的早期理念
- 阿瑟-塞缪尔。创造了 "机器学习 "这一术语
- Frank Rosenblatt: 发明了感知器
- 杰弗里-辛顿 开创了深度学习和神经网络
- Yann LeCun: 卷积神经网络（CNN）。
- 约书亚-本吉奥: 深度学习、循环神经网络 深度学习、递归神经网络
- 安德鲁-吴 Coursera的联合创始人，深度学习研究

！[重要人物](https://chat.openai.com/img/c05/important-people.png)

#### 机器学习的重要人物
### Key Events in Machine Learning

- 1956: Dartmouth Conference, birth of AI and ML
- 1957: Perceptron introduced
- 1986: Backpropagation algorithm for neural networks
- 1997: Support Vector Machines (SVMs)
- 2006: Deep learning, unsupervised pre-training
- 2012: AlexNet, breakthrough in deep learning for computer vision
- 2014: Generative Adversarial Networks (GANs)

![Key Events](https://chat.openai.com/img/c05/key-events.png)

#### Key Events in Machine Learning

### Influential Papers in Machine Learning

- Rosenblatt, F. (1958). The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.
- Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors.
- Cortes, C., & Vapnik, V. (1995). Support-vector networks.
- Hinton, G. E., Osindero, S., & Teh, Y. W. (2006). A fast learning algorithm for deep belief nets.
- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks.
- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial networks.

![Influential Papers](https://chat.openai.com/img/c05/influential-papers.png)

#### Influential Papers in Machine Learning

### Principles of Machine Learning

- Supervised Learning
- Unsupervised Learning
- Semi-Supervised Learning
- Reinforcement Learning
- Evaluation Metrics

![Machine Learning Types](https://chat.openai.com/img/c02/machine-learning-types.png)

#### Types of Machine Learning

### Supervised Learning

- Learning from labeled data
- Classification and Regression
- Examples: Linear Regression, SVM, Decision Trees

<!-- Lecture: Supervised learning is a type of machine learning where the model is trained using labeled data, which contains both input features and corresponding output labels. The objective is to learn a mapping from inputs to outputs, which can be used for future predictions. -->

![Supervised Learning](https://chat.openai.com/img/c02/supervised-learning.png)

#### Supervised Learning

### Unsupervised Learning

- Learning from unlabeled data
- Clustering and Dimensionality Reduction
- Examples: K-means, PCA, t-SNE

<!-- Lecture: Unsupervised learning is a type of machine learning that deals with unlabeled data. The goal is to discover underlying patterns or structure in the data, such as grouping similar data points together (clustering) or reducing the dimensionality of the data for visualization and analysis. -->

![Unsupervised Learning](https://chat.openai.com/img/c02/unsupervised-learning.png)

#### Unsupervised Learning
###机器学习的关键事件

- 1956: 达特茅斯会议，人工智能和ML的诞生
- 1957: 引入感知器
- 1986: 神经网络的反向传播算法
- 1997年：支持向量机（SVMs）。
- 2006: 深度学习，无监督的预训练
- 2012: AlexNet，计算机视觉深度学习的突破性进展
- 2014: 生成对抗网络（GANs）。

！[关键事件](https://chat.openai.com/img/c05/key-events.png)

#### 机器学习中的关键事件

###机器学习中具有影响力的论文

- Rosenblatt, F. (1958). The Perceptron: 大脑中信息存储和组织的概率模型。
- Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). 通过反向传播的错误学习表征。
- Cortes, C., & Vapnik, V. (1995). Support-vector网络.
- Hinton, G. E., Osindero, S., & Teh, Y. W. (2006). A fast learning algorithm for deep belief nets.
- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). 用深度卷积神经网络进行ImageNet分类。
- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). 生成式对抗性网络。

! [Influential Papers](https://chat.openai.com/img/c05/influential-papers.png)

#### 机器学习领域有影响力的论文

###机器学习的原理

- 监督下的学习
- 无监督学习
- 半监督学习
- 强化学习
- 评估指标

![机器学习类型](https://chat.openai.com/img/c02/machine-learning-types.png)

#### 机器学习的类型

### 监督式学习

- 从标记的数据中学习
- 分类和回归
- 例子。线性回归、SVM、决策树

<！--讲座。监督学习是机器学习的一种类型，在这种学习中，模型是使用标记的数据来训练的，这些数据包含输入特征和相应的输出标签。其目的是学习从输入到输出的映射，这可用于未来的预测。-->

![监督学习](https://chat.openai.com/img/c02/supervised-learning.png)

#### 监督学习

### 无监督学习

- 从未标记的数据中学习
- 聚类和降维
- 例子。K-means, PCA, t-SNE

<！--讲座。无监督学习是一种处理无标签数据的机器学习。其目的是发现数据中的潜在模式或结构，例如将类似的数据点归类（聚类）或降低数据的维度，以便进行可视化和分析。-->

![无监督学习](https://chat.openai.com/img/c02/unsupervised-learning.png)

#### 无监督学习
### Semi-Supervised Learning

- Learning from partially labeled data
- Combining supervised and unsupervised techniques
- Examples: Pseudo-labeling, self-training

<!-- Lecture: Semi-supervised learning is a type of machine learning that uses a combination of labeled and unlabeled data for training. The idea is to leverage the large amount of available unlabeled data to improve the performance of the model trained on the smaller labeled dataset. -->

![Semi-Supervised Learning](https://chat.openai.com/img/c02/semi-supervised-learning.png)

#### Semi-Supervised Learning

### Reinforcement Learning

- Learning from interaction with the environment
- Agent, environment, actions, and rewards
- Examples: Q-learning, Deep Q-Networks, Policy Gradients

<!-- Lecture: Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with its environment. The agent receives feedback in the form of rewards or penalties and tries to maximize the cumulative rewards over time by learning an optimal policy. -->

![Reinforcement Learning](https://chat.openai.com/img/c02/reinforcement-learning.png)

#### Reinforcement Learning

### ＃＃＃半监督学习

- 从部分标记的数据中学习
- 结合有监督和无监督的技术
- 例子。伪标签，自我训练

<！--讲座。半监督学习是机器学习的一种类型，它使用标记的和未标记的数据组合进行训练。其想法是利用大量可用的无标签数据来提高在较小的有标签数据集上训练的模型的性能。-->

![半监督学习](https://chat.openai.com/img/c02/semi-supervised-learning.png)

#### 半监督学习（Semi-Supervised Learning

### 强化学习

- 从与环境的互动中学习
- 代理人、环境、行动和奖励
- 例子。Q-learning, Deep Q-Networks, Policy Gradients

<！--讲座。强化学习是一种机器学习，代理通过与环境的互动来学习做决定。代理人以奖励或惩罚的形式接收反馈，并试图通过学习最优策略，在一段时间内使累积奖励最大化。-->

![强化学习](https://chat.openai.com/img/c02/reinforcement-learning.png)

#### 强化学习